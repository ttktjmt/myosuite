{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_tFJt7L5c3r"
      },
      "source": [
        "# 2024 NeurIPS - MyoChallenge\n",
        "\n",
        "## <center> Welcome to the [**2024 NeurIPS - MyoChallenge:  Physiological Dexterity and Agility in Enhanced Humans**](https://sites.google.com/view/myosuite/myochallenge/myochallenge-2024) </center>\n",
        "\n",
        "In the last tutorial: https://colab.research.google.com/drive/1AqC1Y7NkRnb2R1MgjT3n4u02EmSPem88#scrollTo=-mAnRvYjIS4d, you have learned how to quickly train a short policy that is likely to produce ***random actions***, and ***how to visualize it***.\n",
        "\n",
        "This tutorial will help new comers (like you!) to get started on training a policy just that of a baseline. In this tutorial you will learn:\n",
        "\n",
        "\n",
        "1.   How to start a training script that can reproduce the baseline.\n",
        "2.   How to tune the reward dictionary\n",
        "3.   How to access new attributes (e.g., MPL joint angles) and integrate them into your training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjyafsum6WsQ"
      },
      "source": [
        "# 1. Setting the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exBCwdGj6PJj",
        "outputId": "6a8c9d3a-d1d8-4728-d13e-c7fc6d2c3952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python-headless in ./venv/lib/python3.10/site-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in ./venv/lib/python3.10/site-packages (from opencv-python-headless) (2.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install myosuite==2.5.0 --quiet\n",
        "!pip install \"stable-baselines3[extra]\" --quiet\n",
        "!pip install tqdm --quiet\n",
        "!pip install mujoco==3.1.2 --quiet\n",
        "!pip install sk-video --quiet\n",
        "!pip install torch --quiet\n",
        "!pip install opencv-python-headless\n",
        "# %env MUJOCO_GL=egl\n",
        "import mujoco"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqwq5TDt6Y7f"
      },
      "source": [
        "### Define a method to show the rendering inside the Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o4eknDN6bie",
        "outputId": "d960f739-3fc0-4932-db79-67cc15c6ddd7"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def show_video(video_path, video_width = 400):\n",
        "\n",
        "  video_file = open(video_path, \"r+b\").read()\n",
        "\n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  return HTML(f\"\"\"<video autoplay width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv8V5bxZ6euC"
      },
      "source": [
        "### All the `MyoSuite` imports needed to run this tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYuTSaha6hOC",
        "outputId": "7a54ecb8-1c1b-45d2-a14b-a0c6ba65d8ba"
      },
      "outputs": [],
      "source": [
        "import myosuite\n",
        "from myosuite.utils import gym\n",
        "import skvideo.io\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime\n",
        "import time\n",
        "import torch\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv # SubprocVecEnv is for pararrrel processing, DummyVecEnv is for sequential processing\n",
        "from stable_baselines3.common.callbacks import EvalCallback, CallbackList, BaseCallback\n",
        "from tqdm import tqdm_notebook as tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C2cDmWb6zPi"
      },
      "source": [
        "# How to Train the Baselines?\n",
        "\n",
        "The behavior of the baseline was not trained under one iterations, but requires multiple rounds of reward tuning via [curriculum learning](https://ronan.collobert.com/pub/2009_curriculum_icml.pdf). The basic steps to break it done follows closely to the [Lattice solution](https://github.com/amathislab/myochallenge-lattice) from last year.\n",
        "\n",
        "1. First train the myoHand to be as close to the object as possible.\n",
        "2. Train the fingers of the myoHand to wrap around the object.\n",
        "3. Lift the object with myoHand.\n",
        "4. Move the object and myoHand as close to MPL as possible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhYHctDc9Zqu"
      },
      "source": [
        "### Making N parallel envs with seeding, Starting the Training, and Logging the Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5Uok01K6yuK",
        "outputId": "f516f7d7-61f4-4c74-9a21-a8e2c96b68a4"
      },
      "outputs": [],
      "source": [
        "def make_env(env_name, idx, seed=0):\n",
        "    def _init():\n",
        "        env = gym.make(env_name)\n",
        "        env.seed(seed + idx)\n",
        "        return env\n",
        "    return _init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90AZl0bayMRa",
        "outputId": "216609c0-48bb-4d3e-d2c3-6458bebde395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Observation shape: (array([ 0.0000e+00, -2.7804e-01,  1.1771e-01, -1.1772e-01,  2.7805e-01,\n",
            "       -5.6432e-02,  4.5516e-01,  2.0484e-01, -2.0479e-01, -4.5521e-01,\n",
            "        5.6472e-02,  2.5589e-01,  1.1482e+00, -2.5589e-01,  2.7913e-01,\n",
            "        8.4482e-01, -9.9850e-02,  2.4882e-01,  3.2815e-02, -3.1963e-01,\n",
            "        1.7829e-01,  1.2259e-01,  1.1385e-01,  1.5645e-01,  1.7121e-01,\n",
            "        7.7256e-02,  3.1670e-02,  1.4087e-01,  1.6445e-01,  7.7208e-02,\n",
            "        3.0900e-02,  1.2639e-01,  1.3858e-01,  6.5366e-02,  2.2882e-02,\n",
            "        1.1718e-01,  8.9067e-02,  3.0114e-02,  2.0508e-02,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  4.9498e-01, -1.0749e+00,  5.5978e-01,\n",
            "        1.2607e+00, -2.3550e-01, -8.8410e-02, -2.0800e-01,  5.5890e-01,\n",
            "        2.9870e-01,  5.3560e-01,  2.7248e-01,  2.7600e-01,  4.3960e-01,\n",
            "        6.8800e-01,  2.4150e-01,  2.2765e-01,  8.3040e-01,  4.2090e-01,\n",
            "        8.6250e-02,  3.5717e-01,  5.5900e-01,  0.0000e+00,  2.3978e-01,\n",
            "        2.8653e-01,  0.0000e+00,  3.4500e-02, -4.0002e-01,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "       -4.0002e-01, -2.0007e-01,  1.1540e+00,  4.7769e-04, -4.8443e-04,\n",
            "       -7.0711e-01,  7.0711e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        0.0000e+00], dtype=float32), {})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ta747375ki/myosuite/venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_reward_dict to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_reward_dict` for environment variables or `env.get_wrapper_attr('get_reward_dict')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "BimanualEnvV1.get_reward_dict() missing 1 required positional argument: 'obs_dict'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m obs \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObservation shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, obs)\n\u001b[0;32m----> 5\u001b[0m reward_dict \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reward_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReward Dictionary:\u001b[39m\u001b[38;5;124m\"\u001b[39m, reward_dict)\n",
            "\u001b[0;31mTypeError\u001b[0m: BimanualEnvV1.get_reward_dict() missing 1 required positional argument: 'obs_dict'"
          ]
        }
      ],
      "source": [
        "env_name = 'myoChallengeBimanual-v0'\n",
        "env = gym.make(env_name)\n",
        "obs = env.reset()\n",
        "print(\"Observation shape:\", obs)\n",
        "reward_dict = env.get_reward_dict()\n",
        "print(\"Reward Dictionary:\", reward_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Mv4WEyLN9eTU",
        "outputId": "8a25d176-dbf8-47c8-ebde-d884974e5a9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ta747375ki/myosuite/venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_wrapper_attr('seed')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Begin training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ta747375ki/myosuite/venv/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n",
            "/home/ta747375ki/myosuite/venv/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval num_timesteps=40000, episode_reward=-253.59 +/- 183.68\n",
            "Episode length: 250.00 +/- 0.00\n",
            "New best mean reward!\n",
            "Eval num_timesteps=80000, episode_reward=-181.95 +/- 114.63\n",
            "Episode length: 250.00 +/- 0.00\n",
            "New best mean reward!\n",
            "Eval num_timesteps=120000, episode_reward=-195.82 +/- 100.65\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=160000, episode_reward=-248.18 +/- 83.38\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=200000, episode_reward=-304.17 +/- 83.20\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=240000, episode_reward=-353.84 +/- 59.09\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=280000, episode_reward=-305.64 +/- 99.96\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=320000, episode_reward=-321.86 +/- 93.93\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=360000, episode_reward=-352.38 +/- 82.83\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=400000, episode_reward=-144.44 +/- 113.84\n",
            "Episode length: 250.00 +/- 0.00\n",
            "New best mean reward!\n",
            "Eval num_timesteps=440000, episode_reward=-243.52 +/- 132.16\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=480000, episode_reward=-256.44 +/- 102.30\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=520000, episode_reward=-147.26 +/- 135.95\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=560000, episode_reward=-295.33 +/- 53.27\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=600000, episode_reward=-262.76 +/- 34.04\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=640000, episode_reward=-246.95 +/- 32.34\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=680000, episode_reward=-178.49 +/- 115.08\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=720000, episode_reward=-248.47 +/- 53.34\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=760000, episode_reward=-312.37 +/- 240.92\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=800000, episode_reward=-141.73 +/- 98.60\n",
            "Episode length: 250.00 +/- 0.00\n",
            "New best mean reward!\n",
            "Eval num_timesteps=840000, episode_reward=-177.41 +/- 141.37\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=880000, episode_reward=-130.08 +/- 76.93\n",
            "Episode length: 250.00 +/- 0.00\n",
            "New best mean reward!\n",
            "Eval num_timesteps=920000, episode_reward=-119.36 +/- 49.09\n",
            "Episode length: 250.00 +/- 0.00\n",
            "New best mean reward!\n",
            "Eval num_timesteps=960000, episode_reward=-167.07 +/- 37.27\n",
            "Episode length: 250.00 +/- 0.00\n",
            "Eval num_timesteps=1000000, episode_reward=-261.22 +/- 236.71\n",
            "Episode length: 250.00 +/- 0.00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7fc942a8a020>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check if GPU is available\n",
        "print(torch.cuda.is_available())\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# Using time to define the unique naming\n",
        "start_time = time.time()\n",
        "time_now = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "\n",
        "# Initiate N parallel envs and create them\n",
        "num_cpu = 4\n",
        "env_name = 'myoChallengeBimanual-v0'\n",
        "envs = DummyVecEnv([make_env(env_name, i) for i in range(num_cpu)]) # This creates all envs in RAM\n",
        "\n",
        "# Define your own log path\n",
        "log_path = './MPL_baselines/policy_best_model/' + env_name + '/' + time_now + '/'\n",
        "\n",
        "# Define how frequent you want to evaluate the model, where it is logged\n",
        "eval_callback = EvalCallback(envs, best_model_save_path=log_path, log_path=log_path, eval_freq=10000, deterministic=True, render=False)\n",
        "\n",
        "print('Begin training')\n",
        "\n",
        "# Define your policy parameters based on your need.\n",
        "policy_kwargs = {\n",
        "'activation_fn': torch.nn.modules.activation.ReLU,\n",
        "'net_arch': {'pi': [256, 256], 'vf': [256, 256]}\n",
        "}\n",
        "\n",
        "#start the training with PPO\n",
        "model = PPO('MlpPolicy', envs, verbose=0, ent_coef= 0.001, policy_kwargs =policy_kwargs, device=device, batch_size=512)\n",
        "callback = CallbackList([eval_callback])\n",
        "model.learn(total_timesteps=1000000, tb_log_name=env_name + \"_\" + time_now, callback=callback)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BStdwgKP-Vbt"
      },
      "source": [
        "## Continuing Training with Curriculum Learning.\n",
        "\n",
        "After you have achieved a satisfying result for first step. You can use curriculum learning so policy will build upon what it has already learned in the past training. You can define the new model as:\n",
        "\n",
        "\n",
        "```\n",
        "model_num =   '2024_07_11_16_05_18' # Just an example, not a real policy loaded.\n",
        "model = PPO.load('./MPL_baselines/policy_best_model'+ '/'+ env_name + '/' + model_num + r'/best_model', envs, verbose = 0, ent_coeff = 0.01, policy_kwargs = policy_kwargs)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny9CVXHe_FbC"
      },
      "source": [
        "## Visualizing the Policy\n",
        "\n",
        "To visualize the policy, follow **Rendering your policy** in [Tutorial 1](https://colab.research.google.com/drive/1AqC1Y7NkRnb2R1MgjT3n4u02EmSPem88#scrollTo=i4w5MRvmXr8k)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7c8fdadec05e4d658b2c3f27f5b80e31",
            "cbdb437d589e4699be29a307b89eb138",
            "b45dd8280fb947f2911a7520c3414101",
            "e33397c61e314f2f9c04392e3bc77d56",
            "f68eb661afa843f18a6ec9bbd29d5856",
            "e884c3c392ee4031a541b11babfb29e7",
            "e3f8b334eef4499f9f33970e12f0123b",
            "b85ed15f7b6c435bb87449cd674655e4",
            "6a5deca06be7433ab1b61b0dd15e96ed",
            "3ab06a9418a54a4a8c73300e56abb6a1",
            "4316ec1b048b491e9956f64cc95bc9d3"
          ]
        },
        "id": "NIvTdkUrdAq-",
        "outputId": "0d061481-9563-4436-ecb1-a8bbe3292a29"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ta747375ki/myosuite/venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_wrapper_attr('seed')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "*\n",
            "====================\n",
            "*\n",
            "====================\n",
            "*\n",
            "====================\n",
            "*\n",
            "====================\n",
            "*\n",
            "===================="
          ]
        }
      ],
      "source": [
        "env_name = 'myoChallengeBimanual-v0'\n",
        "model_id = '2024_09_06_01_27_46_5000000'\n",
        "num_cpu = 4\n",
        "envs = DummyVecEnv([make_env(env_name, i) for i in range(num_cpu)])\n",
        "policy_kwargs = {\n",
        "'activation_fn': torch.nn.modules.activation.ReLU,\n",
        "'net_arch': {'pi': [256, 256], 'vf': [256, 256]}\n",
        "}\n",
        "model = PPO.load('./MPL_baselines/policy_best_model' + '/' + env_name + '/' + model_id + r'/best_model', envs, verbose = 0, ent_coef = 0.01, policy_kwargs = policy_kwargs)\n",
        "\n",
        "# Render trained policy\n",
        "frames = []\n",
        "env = gym.make(env_name)\n",
        "for _ in range(5): # 5 random targets\n",
        "    print(\"\\n*\")\n",
        "    env.reset()\n",
        "    ep_rewards = []\n",
        "    done = False\n",
        "    obs = env.reset()\n",
        "    for i in range(1, 201):\n",
        "        if i%10 == 0: print(\"=\", end=\"\")\n",
        "        obs = env.obsdict2obsvec(env.obs_dict, env.obs_keys)[1]\n",
        "        # get the next action from the policy\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        geom_1_indices = np.where(env.sim.model.geom_group == 1)\n",
        "        env.sim.model.geom_rgba[geom_1_indices, 3] = 0\n",
        "        frame = env.sim.renderer.render_offscreen(\n",
        "                            width=800,\n",
        "                            height=800,\n",
        "                            camera_id=1)\n",
        "        frames.append(frame)\n",
        "        # take an action based on the current observation\n",
        "        obs, reward, done, info, _ = env.step(action)\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('videos/output.mp4',fourcc, 20.0, (400,400))\n",
        "\n",
        "for i in range(len(frames)):\n",
        "    out.write(cv2.cvtColor(frames[i], cv2.COLOR_RGB2BGR))\n",
        "\n",
        "out.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cih082tY_bzh"
      },
      "source": [
        "# How to tune your reward?\n",
        "\n",
        "Tuning reward is one of the most important part in achieving the baseline behavior, as well as getting start with the challenge. In this part, we suggest that you ***git-clone*** the myoChallenge2024 template, which will be released soon, so you don't have to adjust the source package. For now you can try cloning MyoSuite.\n",
        "\n",
        "Step 1: Navigate to the base env\n",
        "`%cd /usr/local/yourpath/myosuite/myosuite/envs/myo/myochallenge`\n",
        "\n",
        "Step 2: Open the bimanual_v0.py\n",
        "\n",
        "Step 3: Add or adjust the reward based on your need in the function [get_reward_dict](https://github.com/MyoHub/myosuite/blob/ec185ab58afc26711a2f18fd3e6b0cf817964f42/myosuite/envs/myo/myochallenge/bimanual_v0.py#L205C9-L205C24).\n",
        "\n",
        "Step 4: Update your new reward term and weights in [DEFAULT_RWD_KEYS_AND_WEIGHTS](https://github.com/MyoHub/myosuite/blob/ec185ab58afc26711a2f18fd3e6b0cf817964f42/myosuite/envs/myo/myochallenge/bimanual_v0.py#L26C5-L26C33)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5iFYmeECf2e"
      },
      "source": [
        "# How to access new parameters, such as the ones of MPL?\n",
        "\n",
        "There are different APIs from MuJoCo to call joint angle, positions, orientation, etc. You can explore how some of these is defined in the [get_obs_dict](https://github.com/MyoHub/myosuite/blob/ec185ab58afc26711a2f18fd3e6b0cf817964f42/myosuite/envs/myo/myochallenge/bimanual_v0.py#L146).\n",
        "\n",
        "As well as consulting the MuJoCo documentation page: https://mujoco.readthedocs.io/en/stable/APIreference/index.html"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ab06a9418a54a4a8c73300e56abb6a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4316ec1b048b491e9956f64cc95bc9d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a5deca06be7433ab1b61b0dd15e96ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c8fdadec05e4d658b2c3f27f5b80e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbdb437d589e4699be29a307b89eb138",
              "IPY_MODEL_b45dd8280fb947f2911a7520c3414101",
              "IPY_MODEL_e33397c61e314f2f9c04392e3bc77d56"
            ],
            "layout": "IPY_MODEL_f68eb661afa843f18a6ec9bbd29d5856"
          }
        },
        "b45dd8280fb947f2911a7520c3414101": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b85ed15f7b6c435bb87449cd674655e4",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a5deca06be7433ab1b61b0dd15e96ed",
            "value": 5
          }
        },
        "b85ed15f7b6c435bb87449cd674655e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbdb437d589e4699be29a307b89eb138": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e884c3c392ee4031a541b11babfb29e7",
            "placeholder": "​",
            "style": "IPY_MODEL_e3f8b334eef4499f9f33970e12f0123b",
            "value": "100%"
          }
        },
        "e33397c61e314f2f9c04392e3bc77d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ab06a9418a54a4a8c73300e56abb6a1",
            "placeholder": "​",
            "style": "IPY_MODEL_4316ec1b048b491e9956f64cc95bc9d3",
            "value": " 5/5 [30:20&lt;00:00, 364.54s/it]"
          }
        },
        "e3f8b334eef4499f9f33970e12f0123b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e884c3c392ee4031a541b11babfb29e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f68eb661afa843f18a6ec9bbd29d5856": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
